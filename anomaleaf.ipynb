{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = 'data/tomato/train'\n",
    "test_dir = 'data/tomato/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Rescaling and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n",
    "    input_shape=(112, 112, 3)),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomWidth(0.2),\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "], name =\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Datasets (Shuffle and Prefetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (112, 112)\n",
    "BATCH_SIZE = 32\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory = train_dir,\n",
    "    image_size = IMG_SIZE,\n",
    "    label_mode = 'categorical',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed=42\n",
    ").cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory = test_dir,\n",
    "    image_size = IMG_SIZE,\n",
    "    label_mode = 'categorical',\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = test_data.class_names\n",
    "valid_data = test_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "for image_batch,label_batch in train_data.take(1):\n",
    "    for i in range(0,12):\n",
    "        plt.subplot(3,4,i+1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint32\"))\n",
    "        plt.title(class_names[np.argmax(label_batch[i])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmented Image View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for image_batch,label_batch in train_data.take(1):\n",
    "    augmented_image_batch = data_augmentation(image_batch)\n",
    "    image_plt_len = len(image_batch) if len(image_batch) < 4 else 4\n",
    "    for i in range(0, image_plt_len):\n",
    "        plt.subplot(image_plt_len,2,2*i+1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint32\"))\n",
    "        plt.title(class_names[np.argmax(label_batch[i])])\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(image_plt_len,2,2*i+2)\n",
    "        plt.imshow(augmented_image_batch[i])\n",
    "        plt.title(f\"augmented\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"CheckPoint/cp.ckpt\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax', name='output_layers')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    validation_data = test_data,\n",
    "    validation_steps = len(test_data),\n",
    "    callbacks = [\n",
    "        checkpoint_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plot_loss_curve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  plt.figure(figsize=(12,6))\n",
    "  # Plot loss\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  # Plot accuracy\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
