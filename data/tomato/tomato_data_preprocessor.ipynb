{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a9625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "#from rembg import remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a72e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories(path):\n",
    "    # Get list of all files and directories in the given path\n",
    "    contents = os.listdir(path)\n",
    "    \n",
    "    # Filter out only directories\n",
    "    directories = [content for content in contents if os.path.isdir(os.path.join(path, content))]\n",
    "    \n",
    "    return directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee42010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(directory_list)\n",
    "# make sure to stick with rgb images\n",
    "# make sure wwhen training the model, the pixel intensity is from 0 to 1 (normalize the images) (make it 0 mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram of data distribution per class (both training and testing)\n",
    "def create_data_hist(samples):\n",
    "    # samples = [(class_name, count), ...]\n",
    "    class_names = [item[0] for item in samples]\n",
    "    num_samples = [item[1] for item in samples]\n",
    "    \n",
    "    for i, name in enumerate(class_names):\n",
    "        print(name, num_samples[i])\n",
    "    \n",
    "    # Plot histogram\n",
    "    plt.bar(class_names, num_samples, color='skyblue')\n",
    "    plt.xlabel('Class Name')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title('Data Distribution Histogram')\n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing our dataset\n",
    "# dataset_type = {'train', 'val'}\n",
    "def create_dataset(dataset_type):\n",
    "    directory_list = get_directories(f'./{dataset_type}')\n",
    "    data = []\n",
    "    CATEGORIES = directory_list\n",
    "    DATADIR = f'./{dataset_type}/'\n",
    "    samples = []\n",
    "    classdict = {}\n",
    "    # category number: category name\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        count = 0\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        classdict[class_num] = category\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                #remove background\n",
    "                #img_array = remove(img_array)\n",
    "                new_arr = np.moveaxis(img_array, -1, 0)\n",
    "                data.append((new_arr, class_num, img))\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                pass\n",
    "        samples.append((category, count))\n",
    "\n",
    "    # If the class is 'Tomato___healthy', keep 1000 instances, else keep 400 instances\n",
    "    balanced_data = []\n",
    "    classlens = [0,0,0,0,0,0,0,0,0,0]\n",
    "    a = False\n",
    "    for d in data:\n",
    "        # d[2] has the string \"_HL\" in it, it is a healthy tomato leaf image\n",
    "        if not a and d[2].find(\"_HL\") != -1:\n",
    "            a = True\n",
    "            print(\"Health class:\",d[1])\n",
    "            print(classdict[d[1]])\n",
    "        if d[1] == 2 and classlens[d[1]] < 1000:\n",
    "            balanced_data.append(d)\n",
    "            classlens[d[1]] += 1\n",
    "        else:\n",
    "            if classlens[d[1]] < 400:\n",
    "                balanced_data.append(d)\n",
    "                classlens[d[1]] += 1\n",
    "\n",
    "    create_data_hist(samples)  # Display original data distribution\n",
    "    create_data_hist([('Tomato___healthy', 1000)] + [('Anomaly', 400) for _ in range(len(CATEGORIES)-1)])  # Display balanced data distribution\n",
    "    \n",
    "    # Shuffle the balanced data\n",
    "    random.shuffle(balanced_data)\n",
    "\n",
    "    return (balanced_data, classdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ab3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, name):\n",
    "    # Dumping training data\n",
    "    out = name + \".pickle\"\n",
    "    pickle_out = open(out, \"wb\")\n",
    "    pickle.dump(data[0], pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3e482ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t_data \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m t_data[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[1;34m(dataset_type)\u001b[0m\n\u001b[0;32m     19\u001b[0m img_array \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path,img))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#remove background\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m img_array \u001b[38;5;241m=\u001b[39m \u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m new_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(img_array, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     23\u001b[0m data\u001b[38;5;241m.\u001b[39mappend((new_arr, class_num, img))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rembg\\bg.py:135\u001b[0m, in \u001b[0;36mremove\u001b[1;34m(data, alpha_matting, alpha_matting_foreground_threshold, alpha_matting_background_threshold, alpha_matting_erode_size, session, only_mask, post_process_mask)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     session \u001b[38;5;241m=\u001b[39m new_session(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu2net\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 135\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m cutouts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m masks:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rembg\\session_simple.py:12\u001b[0m, in \u001b[0;36mSimpleSession.predict\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, img: PILImage) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[PILImage]:\n\u001b[1;32m---> 12\u001b[0m     ort_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.485\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.456\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.406\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.229\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.225\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     pred \u001b[38;5;241m=\u001b[39m ort_outs[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m, :, :]\n\u001b[0;32m     21\u001b[0m     ma \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(pred)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:200\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    198\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t_data = create_dataset('train')\n",
    "train_data = t_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306be20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee960a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting images\n",
    "image = train_data[100][0]\n",
    "blue_channel, green_channel, red_channel = [image[0], image[1], image[2]]\n",
    "\n",
    "# grayscale image\n",
    "new_img = np.moveaxis(image, 0, -1)\n",
    "gray_image = cv2.cvtColor(new_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "# Plot each channel separately\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(blue_channel, cmap='Blues')\n",
    "plt.title('Blue Channel')\n",
    "# plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(green_channel, cmap='Greens')\n",
    "plt.title('Green Channel')\n",
    "# plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(red_channel, cmap='Reds')\n",
    "plt.title('Red Channel')\n",
    "# plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.title('Grayscale Img')\n",
    "# plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = create_dataset('val')\n",
    "test_data = v_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_data(t_data, \"train_data\")\n",
    "#save_data(v_data, \"val_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_directory(data_and_classes,name):\n",
    "    # Create base directory for the dataset\n",
    "    base_dir = f'./new_dataset/{name}'\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    data = data_and_classes[0]\n",
    "    classes = data_and_classes[1]\n",
    "    print (\"classes\", classes)\n",
    "    # Iterate over the data, which is expected to be a list of tuples (image_array, label)\n",
    "    for idx, (image_array, label, imgname) in enumerate(data):\n",
    "        # Create directory for each class if it doesn't exist\n",
    "        class_dir = os.path.join(base_dir, classes[label])\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        \n",
    "        # Define path for the image to be saved\n",
    "        image_path = os.path.join(class_dir, imgname)\n",
    "        \n",
    "        # Save the image\n",
    "        new_arr = np.moveaxis(image_array, 0, -1)\n",
    "        cv2.imwrite(image_path, cv2.cvtColor(new_arr, cv2.COLOR_RGB2BGR))  # Convert back to BGR for saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db07d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_directory(t_data, \"train\")\n",
    "create_dataset_directory(v_data, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085d7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf_cse120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
